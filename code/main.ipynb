{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2cc13a-1f4b-4dc9-89d5-8f4bc5dd9601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T12:39:39.969611Z",
     "iopub.status.busy": "2022-06-18T12:39:39.969440Z",
     "iopub.status.idle": "2022-06-18T12:39:50.101201Z",
     "shell.execute_reply": "2022-06-18T12:39:50.100423Z",
     "shell.execute_reply.started": "2022-06-18T12:39:39.969583Z"
    },
    "tags": []
   },
   "source": [
    "# 基于高度修改的Deeplab V3+模型的遥感图像分割方案\n",
    "\n",
    "**25_天使天才天王队**\n",
    "\n",
    "## 摘要\n",
    "\n",
    "我们采用了**经过我们深度修改的Deeplab V3+模型**，对Decoder部分加入了基于Attention的改进以此增强模型对全局特征的提取能力。以加权的交叉熵和LovaszSoftmaxLoss损失函数训练了96轮，使用余弦学习率衰减策略和CutMix数据增强。达到了65%的mIOU\n",
    "\n",
    "## 模型介绍\n",
    "\n",
    "我们采用了经过我们深度修改的Deeplab V3+模型。DeepLab v3+通过encoder-decoder进行多尺度信息的融合，同时保留了Deeplab V3的空洞卷积和ASPP层， 其骨干网络使用了ResNet模型，提高了语义分割的健壮性和运行速率，在 PASCAL VOC 2012 dataset取得了state-of-art performance，89.0mIOU。原版Deeplab V3+的架构如下图\n",
    "\n",
    "![原版Deeplab V3+](https://ai-studio-static-online.cdn.bcebos.com/31e5d281555f47a4a6114b323c9b74d5ce1cf72ea0304d55a5b4a6d3847740af)\n",
    "\n",
    "\n",
    "为了更好地适应我们的任务的特点，即前景-背景不均衡、对全局特征提取能力要求较高的特点，我们对该模型做出了相应修改，主要有以下三点：\n",
    "\n",
    "- 为低阶特征和ASPP模块的输出使用CBAM(Convolutional Block Attention Module)增加Attention机制。\n",
    "\n",
    "- 在Decoder中层的卷积模块前后加入SE(Squeeze Excitation)模块引入Attention机制。\n",
    "\n",
    "- 将Decoder末端的卷积模块改为可变卷积(Deformable Convolution)以提高感受野。\n",
    "\n",
    "作为对比，我们修改后的模型结构如下图\n",
    "\n",
    "![深度修改的Deeplab V3+](https://ai-studio-static-online.cdn.bcebos.com/406d268bf4a14960bb887c897b7b144e2b540096939a4fa6bb6031f56719dbd1)\n",
    "\n",
    "通过在Decoder部分大量引入Attention机制并使用可变卷积加大卷积的感受野，我们有效地提高了mIoU。使该模型更好地满足了我们的任务的要求。虽然显著加深的Decoder使得训练过程变慢，但是大大提升了相应的性能，因此我们认为这是值得的。同时我们也尝试了更换backbone等修改，由于效果和速度的权衡，我们并没有最终采纳这些修改。\n",
    "\n",
    "我们修改的Deeplab V3+模型实现见model/models/deeplabv3p.py，下面给出我们修改的Decoder部分的关键实现：\n",
    "\n",
    "```python\n",
    "class Decoder(nn.Layer):\n",
    "    \"\"\"\n",
    "    Decoder module of DeepLabV3P model\n",
    "    Args:\n",
    "        num_classes (int): The number of classes.\n",
    "        in_channels (int): The number of input channels in decoder module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_classes,\n",
    "                 in_channels,\n",
    "                 align_corners,\n",
    "                 data_format='NCHW'):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.data_format = data_format\n",
    "\n",
    "        self.cbam_low = CBAM(channels=48)\n",
    "        self.cbam_high = CBAM(channels=256)\n",
    "\n",
    "        self.conv_bn_relu1 = layers.ConvBNReLU(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=48,\n",
    "            kernel_size=1,\n",
    "            data_format=data_format)\n",
    "\n",
    "        self.conv_bn_relu2 = layers.SeparableConvBNReLU(\n",
    "            in_channels=304,\n",
    "            out_channels=256,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            data_format=data_format)\n",
    "\n",
    "        self.se_in = SEBlock(channel=256)\n",
    "        self.conv_bn_relu3 = layers.SeparableConvBNReLU(\n",
    "            in_channels=256,\n",
    "            out_channels=256,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            data_format=data_format)\n",
    "        self.se_out= SEBlock(channel=256)\n",
    "\n",
    "        # self.conv = nn.Conv2D(\n",
    "        #     in_channels=256,\n",
    "        #     out_channels=num_classes,\n",
    "        #     kernel_size=1,\n",
    "        #     data_format=data_format)\n",
    "        self.conv = DeformableConvV2(\n",
    "            in_channels=256,\n",
    "            out_channels=num_classes,\n",
    "            kernel_size=1,\n",
    "            data_format=data_format)\n",
    "        \n",
    "        self.align_corners = align_corners\n",
    "\n",
    "    def forward(self, x, low_level_feat):\n",
    "        # CBAM\n",
    "        low_level_feat = self.conv_bn_relu1(low_level_feat)\n",
    "        low_level_feat = self.cbam_low(low_level_feat)\n",
    "\n",
    "        if self.data_format == 'NCHW':\n",
    "            low_level_shape = paddle.shape(low_level_feat)[-2:]\n",
    "            axis = 1\n",
    "        else:\n",
    "            low_level_shape = paddle.shape(low_level_feat)[1:3]\n",
    "            axis = -1\n",
    "        \n",
    "        # CBAM\n",
    "        x = self.cbam_high(x)\n",
    "        x = F.interpolate(\n",
    "            x,\n",
    "            low_level_shape,\n",
    "            mode='bilinear',\n",
    "            align_corners=self.align_corners,\n",
    "            data_format=self.data_format)\n",
    "        x = paddle.concat([x, low_level_feat], axis=axis)\n",
    "\n",
    "        x = self.conv_bn_relu2(x)\n",
    "\n",
    "        # SE\n",
    "        x = self.se_in(x)\n",
    "        x = self.conv_bn_relu3(x)\n",
    "        x = self.se_out(x)\n",
    "\n",
    "        # DCN\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "```\n",
    "\n",
    "下面介绍我们加入的模块：\n",
    "\n",
    "### CBMA模块\n",
    "\n",
    "CBMA出自ECCV 2018的论文[CBAM: Convolutional Block Attention Module](https://openaccess.thecvf.com/content_ECCV_2018/papers/Sanghyun_Woo_Convolutional_Block_Attention_ECCV_2018_paper.pdf)。CBAM作为本文的亮点，将Attention同时运用在Channel和Spatial两个维度上。\n",
    "\n",
    "![CBMA](https://ai-studio-static-online.cdn.bcebos.com/37cd8f14c5a540e6ab26e363d586ed5b8dc4c96ded2e4bbe97312bcd467f49f4)\n",
    "\n",
    "如上图，特征图输入后，先进入通道注意力，基于特征图的宽、高进行 GAP、GMP，然后经过 MLP得到通道的注意力权重，然后通过 Sigmoid 函数获得归一化注意力权重，最后通过乘法逐通道加权到原始输入特征图上，完成通道注意力对原始特征的重新标定。\n",
    "\n",
    "为了获得在空间维度的注意力特征，经通道注意力输出的特征图同样基于特征图的宽度和高度进行全局最大池化和全局平均池化，将特征维度由 H×W 转变成1×1，接着经过卷积核为 7×７的卷积和 Relu 激活函数后降低特征图的维度，然后在经过一次卷积后提升为原来的维度，最后将经过 Sigmoid 激活函数标准化处理后的特征图与通道注意力输出的特征图进行合并，从而在空间和通道两个维度上完成对特征图的重标定。\n",
    "\n",
    "在空间注意力模块中，全局平均池化和最大池化获得了空间注意力特征，通过两个卷积建立了空间特征间的相关性，同时保持了输入输出维度的不变。通过卷积核为 7×７的卷积操作，极大地减少了参数和计算量，有利于建立高维度的空间特征相关性。经过 CBAM 后，新的特征图将得到通道和空间维度上的注意力权重，大大提高了各个特征在通道和空间上的联系，更有利于提取目标的有效特征。\n",
    "\n",
    "我们的CBMA实现在model/ops/cbam.py中，下面是详细的代码实现：\n",
    "\n",
    "```python\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "\n",
    "class ChannelAttention(nn.Layer):\n",
    "    def __init__(self, in_planes, rotio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2D(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2D(1)\n",
    "\n",
    "        self.sharedMLP = nn.Sequential(\n",
    "            nn.Conv2D(in_planes, in_planes // rotio , 1, bias_attr=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(in_planes // rotio, in_planes, 1, bias_attr=False))\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avgout = self.sharedMLP(self.avg_pool(x))\n",
    "        maxout = self.sharedMLP(self.max_pool(x))\n",
    "        return self.sigmoid(avgout + maxout)\n",
    "\n",
    "class SpatialAttention(nn.Layer):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        assert kernel_size in (3,7), \"kernel size must be 3 or 7\"\n",
    "\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "\n",
    "        self.conv = nn.Conv2D(2,1,kernel_size, padding=padding, bias_attr=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avgout = paddle.mean(x, axis=1, keepdim=True)\n",
    "        maxout = paddle.max(x, axis=1, keepdim=True)\n",
    "        x = paddle.concat([avgout, maxout], axis=1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class CBAM(nn.Layer):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ca = ChannelAttention(channels,rotio=reduction)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ca(x) * x  \n",
    "        x = self.sa(x) * x \n",
    "\n",
    "        return x\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### SE模块\n",
    "\n",
    "SE模块出自论文[Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507)。结构如下图\n",
    "\n",
    "![SE](https://ai-studio-static-online.cdn.bcebos.com/30ea4e45293e49629adde567bad469ec6eb3f786b01a43bb8e14a7dae407f2f3)\n",
    "\n",
    "SE是一种通道注意力机制。由于特征压缩和FC的存在，其捕获的通道注意力特征是具有全局信息的。它可以自适应的调整各通道的特征响应值，对通道间的内部依赖关系进行建模。SE模块的计算有以下三个步骤：\n",
    "\n",
    "- Squeeze: 沿着空间维度进行特征压缩，将每个二维的特征通道变成一个数，是具有全局的感受野。\n",
    "- Excitation: 每个特征通道生成一个权重，用来代表该特征通道的重要程度。\n",
    "- Reweight：将Excitation输出的权重看做每个特征通道的重要性，通过相乘的方式作用于每一个通道上。\n",
    "\n",
    "我们的SE模块实现在model/ops/se_block.py中，下面给出具体实现代码\n",
    "\n",
    "```python\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "\n",
    "class SEBlock(nn.Layer):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2D(1)  # 全局自适应池化\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias_attr=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channel // reduction, channel, bias_attr=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.shape\n",
    "        y = self.avg_pool(x).reshape([b, c]) # squeeze操作\n",
    "        y = self.fc(y).reshape([b, c, 1, 1]) # FC获取通道注意力权重，是具有全局信息的\n",
    "        return x * y # 注意力作用每一个通道上\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### 可变卷积\n",
    "\n",
    "可变卷积由论文[Deformable Convolutional Networks](https://arxiv.org/pdf/1703.06211.pdf)提出，结构如下图\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1c9dab5d34954fc3be370d2dc19316debc95cfb737ac416c9aad6ee724c0a646)\n",
    "\n",
    "由于固定的几何结构，CNN固有地限制了对几何形状的感知能力。该论文引入了可变卷积来解决这一问题。它在没有额外监督的情况下，通过额外的偏移量来增加模块中的空间采样位置，并从目标任务中学习偏移量。新模块可以替换CNN中的普通卷积模块，并且能通过标准的反向传播进行端到端训练，得到的成为可变卷积网络。我们借助PaddlePaddle的DeformableConv2D算子实现了一个普通卷积层的“即插即用型”替换模块，在model/ops/dcn.py中，下面给出具体实现：\n",
    "\n",
    "```python\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "from paddle.vision.ops import DeformConv2D\n",
    "\n",
    "class DeformableConvV2(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=0,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 weight_attr=None,\n",
    "                 bias_attr=None,\n",
    "                 regularizer=None,\n",
    "                 lr_scale=1.,\n",
    "                 skip_quant=False,\n",
    "                 dcn_bias_regularizer=paddle.regularizer.L2Decay(0.),\n",
    "                 dcn_bias_lr_scale=2.,\n",
    "                 data_format=\"NCHW\"):\n",
    "        super().__init__()\n",
    "        self.offset_channel = 2 * kernel_size**2\n",
    "        self.mask_channel = kernel_size**2\n",
    "\n",
    "        offset_bias_attr = paddle.ParamAttr(\n",
    "            initializer=nn.initializer.Constant(0.),\n",
    "            learning_rate=lr_scale,\n",
    "            regularizer=regularizer)\n",
    "\n",
    "        self.conv_offset = nn.Conv2D(\n",
    "            in_channels,\n",
    "            3 * kernel_size**2,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=(kernel_size - 1) // 2,\n",
    "            weight_attr=paddle.ParamAttr(initializer=nn.initializer.Constant(0.0)),\n",
    "            bias_attr=offset_bias_attr,\n",
    "            data_format=data_format)\n",
    "\n",
    "        if bias_attr:\n",
    "            # in FCOS-DCN head, specifically need learning_rate and regularizer\n",
    "            dcn_bias_attr = paddle.ParamAttr(\n",
    "                initializer=nn.initializer.Constant(value=0),\n",
    "                regularizer=dcn_bias_regularizer,\n",
    "                learning_rate=dcn_bias_lr_scale)\n",
    "        else:\n",
    "            # in ResNet backbone, do not need bias\n",
    "            dcn_bias_attr = False\n",
    "        self.conv_dcn = DeformConv2D(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=(kernel_size - 1) // 2 * dilation,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            weight_attr=weight_attr,\n",
    "            bias_attr=dcn_bias_attr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        offset_mask = self.conv_offset(x)\n",
    "        offset, mask = paddle.split(\n",
    "            offset_mask,\n",
    "            num_or_sections=[self.offset_channel, self.mask_channel],\n",
    "            axis=1)\n",
    "        mask = F.sigmoid(mask)\n",
    "        y = self.conv_dcn(x, offset, mask=mask)\n",
    "        return y\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73979549-4c92-445b-99b2-08c4329e8b56",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "由于我们的修改使得模型的参数量大大增加，为了满足AI Studio单次运行不超过72小时的限制，我们采用了相对复杂的训练方案，具体如下：\n",
    "\n",
    "\n",
    "### 训练策略\n",
    "\n",
    "\n",
    "1. 先使用原版Deeplab V3+网络进行80轮训练，并保存相应参数。该过程的学习率为0.05，使用交叉熵损失，余弦学习率衰减。\n",
    "\n",
    "2. 将参数加载到修改的Deeplan V3+中，冻结Backbone的参数，对Decoder进行32轮的训练。该过程的学习率为0.002，使用加权的交叉熵损失，余弦学习率衰减。\n",
    "\n",
    "3. 解除对Backbone的冻结，再进行64轮训练，使用加权交叉熵和LovaszSoftmaxLoss混合进行训练，使用多项式学习率衰减。\n",
    "\n",
    "该过程虽然较为复杂，但有效地平衡了较大的模型对训练时间的需求同AI Studio的限制之间的矛盾，取得了较好的效果。\n",
    "\n",
    "### 数据增强\n",
    "\n",
    "我们主要使用CutMix进行数据增强。CutMix将CutOut和Mixup结合。CutMix相比于Cutout就是将区域删除操作变成截取另外一张图片一样大小的区域填充该区域，同时改变新图片的标签。我们的数据集类负责对CutMix进行实现，代码文件为model/data/dataset.py。下面给出 CutMix部分的实现：\n",
    "\n",
    "```python\n",
    "    def rand_bbox(self,size, lam):\n",
    "        W,H=size\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = np.int(W * cut_rat)\n",
    "        cut_h = np.int(H * cut_rat)\n",
    "\n",
    "        # uniform\n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "        return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "    def do_cutmix(self,img,lbl):\n",
    "        if not self.enable_cutmix:\n",
    "            return img,lbl\n",
    "        \n",
    "        if random.uniform(0,1)<self.cutmix_threshold:\n",
    "            return img,lbl\n",
    "\n",
    "        idx = random.randrange(1,len(self.files)-1)\n",
    "        nimg,nlbl=self.do_getitem(idx)\n",
    "        bbx1, bby1, bbx2, bby2 = self.rand_bbox(self.img_size, self.cutmix_lambda)#随机产生一个box的四个坐标\n",
    "        img[:, bbx1:bbx2, bby1:bby2] = nimg[:, bbx1:bbx2, bby1:bby2]\n",
    "        lbl[bbx1:bbx2, bby1:bby2] = nlbl[bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        return img,lbl\n",
    "```\n",
    "\n",
    "下面是训练流程的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9874ae4-4088-4cbe-bcfd-4aa52a015fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:36.922210Z",
     "iopub.status.busy": "2022-06-18T14:55:36.921659Z",
     "iopub.status.idle": "2022-06-18T14:55:41.765735Z",
     "shell.execute_reply": "2022-06-18T14:55:41.764967Z",
     "shell.execute_reply.started": "2022-06-18T14:55:36.922184Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: 无法创建目录\"/home/aistudio/external-libraries\": 文件已存在\n",
      "mkdir: 无法创建目录\"/home/aistudio/work/checkpoints\": 文件已存在\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Requirement already satisfied: imgaug in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.6.3)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (8.2.0)\n",
      "Requirement already satisfied: imageio in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (2.6.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.19.5)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (4.1.1.26)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (0.19.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (2.2.3)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.16.0)\n",
      "Requirement already satisfied: Shapely in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (21.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (2021.11.2)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (2.4)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (1.1.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2019.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (56.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from networkx>=2.2->scikit-image>=0.14.2->imgaug) (4.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Requirement already satisfied: paddleseg in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.5.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (4.1.1.26)\n",
      "Requirement already satisfied: visualdl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (2.2.3)\n",
      "Requirement already satisfied: sklearn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (0.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (0.7.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (5.1.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (3.0.12)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (1.6.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (4.27.0)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.21.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.1.5)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.16.0)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.1.1)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (3.14.0)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (0.8.53)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (4.0.1)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.0.0)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (0.7.1.1)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (8.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (2.24.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sklearn->paddleseg) (0.24.2)\n",
      "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddleseg) (2.8.0)\n",
      "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddleseg) (2.4.0)\n",
      "Requirement already satisfied: importlib-metadata<4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddleseg) (4.2.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddleseg) (0.6.1)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (3.0.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (0.16.0)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg) (2019.3)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg) (0.18.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg) (3.9.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (3.0.8)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (2.8.2)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddleseg) (1.3.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddleseg) (2.0.1)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddleseg) (0.10.0)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddleseg) (1.3.4)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddleseg) (1.4.10)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddleseg) (16.7.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddleseg) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddleseg) (2019.9.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddleseg) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddleseg) (1.25.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddleseg) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddleseg) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddleseg) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddleseg) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.0.0->paddleseg) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl>=2.0.0->paddleseg) (56.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!mkdir /home/aistudio/external-libraries\r\n",
    "!mkdir /home/aistudio/work/checkpoints\r\n",
    "\r\n",
    "!pip install imgaug -i https://mirror.baidu.com/pypi/simple\r\n",
    "!pip install paddleseg -i https://mirror.baidu.com/pypi/simple\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e66c14-e14e-4afe-b5d0-80ba5597b220",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 训练过程\n",
    "以下是训练参数，由于CBAM和SE模块使得模型较为难以训练，因此训练72轮。初始学习率为0.005，学习率衰减为余弦衰减。训练过程长约270小时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db17c5b-3e2b-4033-9cc0-82af1ff1f80b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:41.767975Z",
     "iopub.status.busy": "2022-06-18T14:55:41.767400Z",
     "iopub.status.idle": "2022-06-18T14:55:41.773150Z",
     "shell.execute_reply": "2022-06-18T14:55:41.772625Z",
     "shell.execute_reply.started": "2022-06-18T14:55:41.767930Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_parameters = {\n",
    "    \"test_path\":\"/home/aistudio/data/data80164/img_test.zip\", \n",
    "    \"train_path\":\"/home/aistudio/data/data80164/train_and_label.zip\", \n",
    "    \"data_path\":\"/home/aistudio/data/\",                     #要解压的路径\n",
    "    \"label_dict\":{},\n",
    "    \"skip_steps\": 100,\n",
    "    \"save_steps\": 300, \n",
    "    \"image_size\":512,\n",
    "    \"learning_strategy\": {                                    #优化函数相关的配置\n",
    "        \"lr\": 0.005,                                          #超参数学习率\n",
    "        \"cos_decay_T\":100,  \n",
    "        \"step_decay_step\":100,\n",
    "        \"workers\":4,\n",
    "        \"batch_size\":16,\n",
    "        \"epochs\":96,\n",
    "        \"train_iters\":80000\n",
    "    },\n",
    "    \"learning_strategy_warmup\": {                               \n",
    "        \"lr\": 0.001,                                     \n",
    "        \"cos_decay_T\":100,  \n",
    "        \"step_decay_step\":100,\n",
    "        \"workers\":4,\n",
    "        \"batch_size\":8,\n",
    "        \"epochs\":5,\n",
    "        \"train_iters\":80000\n",
    "    },\n",
    "    \"max_items\":80000,\n",
    "    \"checkpoints\": \"/home/aistudio/work/checkpoints\",    \n",
    "    \"pretrained\": \"/home/aistudio/work/pretrained\"         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83776abb-6512-41e8-abda-bc2e4120bbaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:41.774192Z",
     "iopub.status.busy": "2022-06-18T14:55:41.773959Z",
     "iopub.status.idle": "2022-06-18T14:55:42.218734Z",
     "shell.execute_reply": "2022-06-18T14:55:42.218089Z",
     "shell.execute_reply.started": "2022-06-18T14:55:41.774172Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: 无法创建目录\"/home/aistudio/work/checkpoints\": 文件已存在\n",
      "mkdir: 无法创建目录\"/home/aistudio/work/pretrained\": 文件已存在\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/aistudio/work/checkpoints\n",
    "!mkdir /home/aistudio/work/pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd615c-f855-4736-9a40-97dd8455feb0",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "将数据写入文本文件中，并准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9161d795-c6d5-458c-a6e1-f1bebc9f28c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:42.220273Z",
     "iopub.status.busy": "2022-06-18T14:55:42.219882Z",
     "iopub.status.idle": "2022-06-18T14:55:44.337407Z",
     "shell.execute_reply": "2022-06-18T14:55:44.336726Z",
     "shell.execute_reply.started": "2022-06-18T14:55:42.220227Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import json\n",
    "import paddle\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from paddle.io import Dataset\n",
    "import paddle.fluid as fluid\n",
    "from pathlib import Path\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81cb63a-d088-4764-bd8f-337c1caa0da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:44.339561Z",
     "iopub.status.busy": "2022-06-18T14:55:44.339098Z",
     "iopub.status.idle": "2022-06-18T14:55:44.343036Z",
     "shell.execute_reply": "2022-06-18T14:55:44.342514Z",
     "shell.execute_reply.started": "2022-06-18T14:55:44.339531Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "random.seed(datetime.now())\n",
    "np.random.seed(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01109d9b-01d7-4b43-a319-06fe37035ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:44.343941Z",
     "iopub.status.busy": "2022-06-18T14:55:44.343782Z",
     "iopub.status.idle": "2022-06-18T14:55:44.348262Z",
     "shell.execute_reply": "2022-06-18T14:55:44.347732Z",
     "shell.execute_reply.started": "2022-06-18T14:55:44.343922Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unzip_data(src_path,target_path,postfix):\n",
    "    if not os.path.isdir(target_path + postfix):     \n",
    "        z = zipfile.ZipFile(src_path, 'r')\n",
    "        z.extractall(path=target_path + postfix)\n",
    "        z.close()\n",
    "\n",
    "data_path=train_parameters['data_path']\n",
    "\n",
    "unzip_data(train_parameters['train_path'],data_path,\"train\")\n",
    "unzip_data(train_parameters['test_path'],data_path,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d0d5f8e-e3c7-4150-bcf5-8fd9da2ae079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:44.349192Z",
     "iopub.status.busy": "2022-06-18T14:55:44.348977Z",
     "iopub.status.idle": "2022-06-18T14:55:45.125049Z",
     "shell.execute_reply": "2022-06-18T14:55:45.124388Z",
     "shell.execute_reply.started": "2022-06-18T14:55:44.349172Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 66652\n",
      "img_train/T124582.jpg\n",
      "lab_train/T124582.png\n",
      "('img_train/T039627.jpg', 'lab_train/T039627.png')\n"
     ]
    }
   ],
   "source": [
    "datas = []\n",
    "\n",
    "path_base=train_parameters['data_path']+'train/'\n",
    "\n",
    "image_base = path_base +'img_train'   # 训练集原图路径\n",
    "annos_base = path_base +'lab_train'   # 训练集标签路径\n",
    "\n",
    "ids_ = [v.split('.')[0] for v in os.listdir(image_base)]\n",
    "\n",
    "# 将训练集的图像集和标签路径写入datas中\n",
    "for id_ in ids_:\n",
    "    img_pt0 = os.path.join(image_base, '{}.jpg'.format(id_))\n",
    "    img_pt1 = os.path.join(annos_base, '{}.png'.format(id_))\n",
    "    datas.append((img_pt0.replace(path_base, ''), img_pt1.replace(path_base, '')))\n",
    "    if os.path.exists(img_pt0) and os.path.exists(img_pt1):\n",
    "        pass\n",
    "    else:\n",
    "        raise \"path invalid!\"\n",
    "\n",
    "# 打印datas的长度和具体存储例子\n",
    "print('total:', len(datas))\n",
    "print(datas[0][0])\n",
    "print(datas[0][1])\n",
    "print(datas[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da78e02f-fcd9-4dfb-a744-c4c9376b7955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:45.126630Z",
     "iopub.status.busy": "2022-06-18T14:55:45.126142Z",
     "iopub.status.idle": "2022-06-18T14:55:45.188115Z",
     "shell.execute_reply": "2022-06-18T14:55:45.187327Z",
     "shell.execute_reply.started": "2022-06-18T14:55:45.126600Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 66472\n",
      "valid: 180\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 四类标签，这里用处不大，比赛评测是以0、1、2、3类来对比评测的\n",
    "labels = ['建筑', '耕地', '林地',  '其他']\n",
    "\n",
    "# 将labels写入标签文件\n",
    "with open('labels.txt', 'w') as f:\n",
    "    for v in labels:\n",
    "        f.write(v+'\\n')\n",
    "\n",
    "MAX_ITEMS=train_parameters['max_items']\n",
    "EVAL_PORTION=0.015\n",
    "EVAL_MAX=180\n",
    "\n",
    "if len(datas)>MAX_ITEMS:\n",
    "    datas=random.sample(datas,MAX_ITEMS)\n",
    "\n",
    "np.random.seed(5)\n",
    "np.random.shuffle(datas)\n",
    "\n",
    "# 验证集与训练集的划分，0.05表示5%为训练集，95%为训练集\n",
    "split_num = int(EVAL_PORTION*len(datas))\n",
    "split_num = EVAL_MAX if split_num>EVAL_MAX else split_num\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_data = datas[:-split_num]\n",
    "valid_data = datas[-split_num:]\n",
    "\n",
    "# 写入训练集list\n",
    "with open('train_list.txt', 'w') as f:\n",
    "    for img, lbl in train_data:\n",
    "        f.write(img + ' ' + lbl + '\\n')\n",
    "\n",
    "# 写入验证集list\n",
    "with open('valid_list.txt', 'w') as f:\n",
    "    for img, lbl in valid_data:\n",
    "        f.write(img + ' ' + lbl + '\\n')\n",
    "\n",
    "# 打印训练集和测试集大小\n",
    "print('train:', len(train_data))\n",
    "print('valid:', len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794698ca-270e-41fc-a181-f123b760aa1c",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "定义数据集，数据集实现了CutMix数据增强，实现见model/data/dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f089e3e-d556-46b3-a0a2-8bf328d05c12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:45.189544Z",
     "iopub.status.busy": "2022-06-18T14:55:45.189276Z",
     "iopub.status.idle": "2022-06-18T14:55:46.508730Z",
     "shell.execute_reply": "2022-06-18T14:55:46.507981Z",
     "shell.execute_reply.started": "2022-06-18T14:55:45.189519Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model.data.dataset import SegmentDataset\n",
    "\n",
    "img_size_tuple=(train_parameters[\"image_size\"],train_parameters[\"image_size\"])\n",
    "\n",
    "train_dataset=SegmentDataset(base_path=path_base,\n",
    "    file_list='train_list.txt',\n",
    "    img_size=img_size_tuple)\n",
    "\n",
    "eval_dataset=SegmentDataset(base_path=path_base,\n",
    "    file_list='valid_list.txt',\n",
    "    img_size=img_size_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99d40761-eddf-4126-b8b7-62d56a0affac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:46.510297Z",
     "iopub.status.busy": "2022-06-18T14:55:46.509822Z",
     "iopub.status.idle": "2022-06-18T14:55:46.514025Z",
     "shell.execute_reply": "2022-06-18T14:55:46.513449Z",
     "shell.execute_reply.started": "2022-06-18T14:55:46.510269Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assert_is_label(lbl):\n",
    "    assert len(lbl[lbl==0])+len(lbl[lbl==1])+len(lbl[lbl==2])+len(lbl[lbl==3])+len(lbl[lbl==255])==len(lbl.flatten().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f356dab-7cae-4ab0-b83b-b7a741855b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:46.515189Z",
     "iopub.status.busy": "2022-06-18T14:55:46.514872Z",
     "iopub.status.idle": "2022-06-18T14:55:46.541342Z",
     "shell.execute_reply": "2022-06-18T14:55:46.540819Z",
     "shell.execute_reply.started": "2022-06-18T14:55:46.515167Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66472\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(eval_dataset))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "img,lbl=train_dataset[random.randint(0,len(train_dataset)-1)]\n",
    "\n",
    "assert_is_label(lbl)\n",
    "\n",
    "# plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "# plt.show()\n",
    "# plt.imshow(lbl)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2c6834-b39f-409b-a5f0-f4b23374160c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:46.542485Z",
     "iopub.status.busy": "2022-06-18T14:55:46.542106Z",
     "iopub.status.idle": "2022-06-18T14:55:46.563694Z",
     "shell.execute_reply": "2022-06-18T14:55:46.563157Z",
     "shell.execute_reply.started": "2022-06-18T14:55:46.542462Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_lastest():\n",
    "    path=train_parameters['checkpoints']+\"/\"+'best.pdparames'\n",
    "    \n",
    "    if not os.path.exists(train_parameters['checkpoints']):\n",
    "        return None\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    \n",
    "    return path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea44adc4-3d56-4002-887f-5b6dc2934868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:46.564768Z",
     "iopub.status.busy": "2022-06-18T14:55:46.564540Z",
     "iopub.status.idle": "2022-06-18T14:55:46.569743Z",
     "shell.execute_reply": "2022-06-18T14:55:46.569247Z",
     "shell.execute_reply.started": "2022-06-18T14:55:46.564748Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "find_lastest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48db28e5-6b6d-42d3-a92e-e6cb309a58b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:46.571931Z",
     "iopub.status.busy": "2022-06-18T14:55:46.571700Z",
     "iopub.status.idle": "2022-06-18T14:55:46.830297Z",
     "shell.execute_reply": "2022-06-18T14:55:46.829500Z",
     "shell.execute_reply.started": "2022-06-18T14:55:46.571910Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -O work/checkpoints/best.pdparams https://bj.bcebos.com/v1/ai-studio-online/netdisk/40f121450fab4a439525932234ca0d48d91f544fb164434cbb4cb06fe0724037?responseContentDisposition=attachment%3B%20filename%3Dbest0615.pdparames&authorization=bce-auth-v1%2F0ef6765c1e494918bc0d4c3ca3e5c6d1%2F2022-06-15T12%3A10%3A24Z%2F-1%2F%2F8ed73e87997df85c38f1e7d90615232e5978e54f0c2b2bbfe3bc5355d413ffaa\r\n",
    "!wget -O work/pretrained/resnet.tar.gz https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f9aa6-2411-4b2b-b0c1-b86828d24c09",
   "metadata": {},
   "source": [
    "## 模型定义\n",
    "\n",
    "我们采用Deeplab v3+模型。同时在模型的decoder部分加入了Squeeze-Excitation模块和CBAM模块，并将最后一个卷积层换成可变卷积。\n",
    "具体实现见model/models/deeplabv3p.py\n",
    "\n",
    "\n",
    "我们进一步对decoder部分进行改进，通过加入CBAM和SE模块来引入Attention机制，加强了模型对全局特征的提取能力，同时可变卷积的引入大大增强了最后一层卷积的感受野。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a277728e-7811-4f86-8215-ac5495d4110a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:46.831985Z",
     "iopub.status.busy": "2022-06-18T14:55:46.831495Z",
     "iopub.status.idle": "2022-06-18T14:55:46.845649Z",
     "shell.execute_reply": "2022-06-18T14:55:46.845149Z",
     "shell.execute_reply.started": "2022-06-18T14:55:46.831945Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddleseg.core\n",
    "\n",
    "from model.models.deeplabv3p import DeepLabV3P\n",
    "from model.backbones.resnetvd import ResNet50_vd\n",
    "\n",
    "# model:\n",
    "#   type: DeepLabV3P\n",
    "#   backbone:\n",
    "#     type: ResNet50_vd\n",
    "#     output_stride: 8\n",
    "#     multi_grid: [1, 2, 4]\n",
    "#     pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
    "#   num_classes: 19\n",
    "#   backbone_indices: [0, 3]\n",
    "#   aspp_ratios: [1, 12, 24, 36]\n",
    "#   aspp_out_channels: 256\n",
    "#   align_corners: False\n",
    "#   pretrained: null\n",
    "\n",
    "\n",
    "def get_backbone():\n",
    "    backbone = ResNet50_vd(output_stride=8,\n",
    "        multi_grid=[1, 2, 4],\n",
    "        pretrained=\"https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\")\n",
    "    return backbone\n",
    "\n",
    "\n",
    "def get_new_model():\n",
    "    backbone =get_backbone()\n",
    "\n",
    "    model = DeepLabV3P(\n",
    "        num_classes=4,\n",
    "        backbone=backbone,\n",
    "        backbone_indices=[0, 3],\n",
    "        aspp_ratios=[1, 12, 24, 36],\n",
    "        aspp_out_channels=256,\n",
    "        align_corners=True\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def get_trained_model():\n",
    "    trained_path=find_lastest()\n",
    "    if trained_path is None:\n",
    "        return get_new_model()\n",
    "\n",
    "    if not os.path.exists(trained_path):\n",
    "        return get_new_model()\n",
    "\n",
    "    backbone = get_backbone()\n",
    "\n",
    "    model = DeepLabV3P(\n",
    "        num_classes=4,\n",
    "        backbone=backbone,\n",
    "        backbone_indices=[0, 3],\n",
    "        aspp_ratios=[1, 12, 24, 36],\n",
    "        aspp_out_channels=256,\n",
    "        align_corners=True,\n",
    "        pretrained=trained_path\n",
    "    )\n",
    "\n",
    "    if trained_path is not None:\n",
    "        print(\"Load previous state\")\n",
    "        model.set_state_dict(paddle.load(trained_path))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def save_model(model,miou):\n",
    "    print('Model of mIoU {} saving...'.format(miou))\n",
    "    paddle.save(model.state_dict(),  train_parameters['checkpoints']+\"/\"+'best.pdparames')\n",
    "\n",
    "def save_checkpoint(model,epoch):\n",
    "    print('Checkpoint {} saving...'.format(epoch))\n",
    "    paddle.save(model.state_dict(),  train_parameters['checkpoints']+\"/\"+'epoch{}.pdparames'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b34eb09-4d33-4580-9fb3-f12d3d5fd244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:46.846704Z",
     "iopub.status.busy": "2022-06-18T14:55:46.846482Z",
     "iopub.status.idle": "2022-06-18T14:55:46.854140Z",
     "shell.execute_reply": "2022-06-18T14:55:46.853641Z",
     "shell.execute_reply.started": "2022-06-18T14:55:46.846683Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_config = {\n",
    "    \"optimizer\":\"sgd\",\n",
    "    \"scheduler\":\"cosine\",\n",
    "    \"scheduler_verbose\":True\n",
    "}\n",
    "\n",
    "def get_scheduler(model,strategy):\n",
    "    if train_config[\"scheduler\"]==\"cosine\":\n",
    "        return paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=strategy['lr'],\n",
    "            T_max=strategy['cos_decay_T'],\n",
    "            verbose=train_config[\"scheduler_verbose\"])\n",
    "    elif train_config[\"scheduler\"]==\"step\":\n",
    "        return paddle.optimizer.lr.StepDecay(learning_rate=strategy['lr'],\n",
    "            step_size=strategy['step_decay_step'],\n",
    "            gamma=0.8,\n",
    "            verbose=train_config[\"scheduler_verbose\"])\n",
    "    elif train_config[\"scheduler\"]==\"linear\":\n",
    "        return paddle.optimizer.lr.LinearWarmup(\n",
    "            learning_rate=strategy['lr'],\n",
    "            warmup_steps=20,\n",
    "            start_lr=strategy['lr']/100.0,\n",
    "            end_lr=strategy['lr'],\n",
    "            verbose=train_config[\"scheduler_verbose\"])\n",
    "    elif train_config[\"scheduler\"]==\"poly\":\n",
    "        return paddle.optimizer.lr.PolynomialDecay(\n",
    "            learning_rate=strategy['lr'],\n",
    "            decay_steps=strategy['step_decay_step'],\n",
    "            end_lr=strategy['lr']/5.0,\n",
    "            verbose=train_config[\"scheduler_verbose\"])\n",
    "\n",
    "def get_optimizer(model,scheduler):\n",
    "    if train_config[\"optimizer\"]==\"sgd\":\n",
    "        return paddle.optimizer.Momentum(learning_rate=scheduler,\n",
    "                        use_nesterov=True,\n",
    "                        weight_decay= paddle.regularizer.L2Decay(4.0e-5),\n",
    "                        parameters=model.parameters())\n",
    "    elif train_config[\"optimizer\"]==\"adamw\":\n",
    "        return paddle.optimizer.AdamW(learning_rate=scheduler,\n",
    "                        parameters=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5041e4-b5b8-4c5e-9d2f-302ee0246c4f",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "我们使用加权的交叉熵损失和LovaszSoftmaxLoss混合训练，权重是7：3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c86ed1dd-46e3-4f0f-9134-975b285f1363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:46.855011Z",
     "iopub.status.busy": "2022-06-18T14:55:46.854860Z",
     "iopub.status.idle": "2022-06-18T14:55:46.861454Z",
     "shell.execute_reply": "2022-06-18T14:55:46.860960Z",
     "shell.execute_reply.started": "2022-06-18T14:55:46.854993Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from paddleseg.models.losses import LovaszSoftmaxLoss,OhemCrossEntropyLoss,SemanticConnectivityLoss,MixedLoss\n",
    "from model.loss.focal import MultiClassFocalLoss\n",
    "\n",
    "def get_losses():\n",
    "    ce = paddle.nn.CrossEntropyLoss(axis=1,ignore_index=255)\n",
    "\n",
    "    weights = paddle.to_tensor([0.26,0.21,0.25,0.28],dtype='float32')\n",
    "    wce = paddle.nn.CrossEntropyLoss(weight=weights, axis=1,ignore_index=255)\n",
    "\n",
    "    oce = OhemCrossEntropyLoss(ignore_index=255)\n",
    "    \n",
    "    lsl = LovaszSoftmaxLoss(ignore_index=255)\n",
    "\n",
    "    # SCL（Semantic Connectivity-aware Learning）框架，它引入了SC Loss (Semantic Connectivity-aware Loss)，从连通性的角度提升分割结果的质量。支持多类别分割。\n",
    "    sce = SemanticConnectivityLoss(ignore_index=255)\n",
    "\n",
    "    # mixed = MixedLoss([wce,sce,lsl],[0.2,0.4,0.4])\n",
    "    # return mixed\n",
    "    mixed = MixedLoss([wce,lsl],[0.7,0.3])\n",
    "    return mixed\n",
    "\n",
    "def loss_combine(losses):\n",
    "    if not isinstance(losses,list):\n",
    "        return losses \n",
    "    else:\n",
    "        step_loss = paddle.zeros_like(losses[0])\n",
    "        for l in losses:\n",
    "            step_loss+=l\n",
    "        return step_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c1712-39c3-4c15-af37-7a4f0e019f58",
   "metadata": {},
   "source": [
    "## 训练过程\n",
    "\n",
    "以下定义了训练的过程，并输出MIOU。mIoU测度具体计算的实现见metrics/mIoU.py，这里给出关键部分:\n",
    "\n",
    "```python\n",
    "    def _fast_hist(self, label_pred, label_true):\n",
    "        # 找出标签中需要计算的类别,去掉背景\n",
    "        mask = (label_true >= 0) & (label_true < self.num_classes)\n",
    "        # # np.bincount计算了从0到n**2-1这n**2个数中每个数出现的次数，返回值形状(n, n)\n",
    "        hist = np.bincount(\n",
    "            self.num_classes * label_true[mask].astype(int) +\n",
    "            label_pred[mask], minlength=self.num_classes ** 2).reshape(self.num_classes, self.num_classes)\n",
    "        return hist\n",
    "\n",
    "    # 输入：预测值和真实值\n",
    "    # 语义分割的任务是为每个像素点分配一个label\n",
    "    def evaluate(self, predictions, gts):\n",
    "        for lp, lt in zip(predictions, gts):\n",
    "            assert len(lp.flatten()) == len(lt.flatten())\n",
    "            self.hist += self._fast_hist(lp.flatten(), lt.flatten())\n",
    "            \n",
    "        # miou\n",
    "        iou = np.diag(self.hist) / (self.hist.sum(axis=1) + self.hist.sum(axis=0) - np.diag(self.hist))\n",
    "        miou = np.nanmean(iou) \n",
    "\n",
    "        return iou,miou\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b93cf-8e72-4950-bc74-50013d0f9640",
   "metadata": {},
   "source": [
    "## 具体训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53a4b851-e96a-493b-bf7b-cac70e937490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:46.862514Z",
     "iopub.status.busy": "2022-06-18T14:55:46.862318Z",
     "iopub.status.idle": "2022-06-18T14:55:46.880818Z",
     "shell.execute_reply": "2022-06-18T14:55:46.880279Z",
     "shell.execute_reply.started": "2022-06-18T14:55:46.862494Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from metrics.mIoU import IOUMetric\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "miou = IOUMetric(4)\n",
    "\n",
    "def train_one_epoch(model,epoch, epochs,optimizer,scheduler,loss,train_loader):\n",
    "    print('Start Training...')\n",
    "    print('Epoch/Epochs:{}/{}'.format(epoch, epochs))\n",
    "    print('Train...')\n",
    "    train_loss = 0\n",
    "    train_miou = 0\n",
    "    model.train()\n",
    "    for batch_id, (img, label) in tqdm(enumerate(train_loader)):\n",
    "        pred = model(img)\n",
    "        pred=pred[0]\n",
    "        step_loss = loss_combine(loss(pred, label))\n",
    "        train_loss += step_loss.numpy()[0]\n",
    "\n",
    "        # 计算miou, pred: num_loss * NCHW -> NHW \n",
    "        mask = np.argmax(pred.numpy(), axis=1)\n",
    "        iou,step_miou = miou.evaluate(mask[0], label.numpy()[0])\n",
    "        for i in range(1,mask.shape[0]):\n",
    "            # print(mask[i].shape, label.shape)\n",
    "            clsiou,alliou=miou.evaluate(mask[i], label.numpy()[i])\n",
    "            iou+=clsiou\n",
    "            step_miou+=alliou\n",
    "            \n",
    "        step_miou /= mask.shape[0]\n",
    "        iou/=mask.shape[0]\n",
    "        train_miou += step_miou\n",
    "\n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_id + 1) % 100 == 0:\n",
    "            scheduler.step()\n",
    "            print('Epoch/Epochs:{}/{} Batch/Batchs:{}/{} Step Loss:{} Step Miou:{} Class Miou:{}'.format(epoch, epochs, batch_id+1, len(train_loader), \\\n",
    "                                                                                            step_loss.numpy(), step_miou,iou))\n",
    "        optimizer.clear_grad()\n",
    "    \n",
    "    print('Train Loss:{} Train Miou:{}'.format(train_loss/len(train_loader), train_miou/len(train_loader)))\n",
    "\n",
    "def eval_one_epoch(model,epoch, epochs,optimizer,loss,eval_loader):\n",
    "    print('Star Evalution...')\n",
    "    val_loss = 0\n",
    "    val_miou = 0\n",
    "    val_iou=None\n",
    "    model.eval()\n",
    "    for batch_id, (img, label) in tqdm(enumerate(eval_loader)):\n",
    "        pred = model(img)\n",
    "        pred=pred[0]\n",
    "        step_loss = loss_combine(loss(pred, label))\n",
    "        val_loss += step_loss.numpy()[0]\n",
    "\n",
    "        # 计算miou, pred: num_loss * NCHW -> NHW \n",
    "        mask = np.argmax(pred.numpy(), axis=1)\n",
    "        iou,step_miou = miou.evaluate(mask[0], label.numpy()[0])\n",
    "        for i in range(mask.shape[0]):\n",
    "            # print(mask[i].shape, label.shape)\n",
    "            clsiou,alliou=miou.evaluate(mask[i], label.numpy()[i])\n",
    "            iou+=clsiou\n",
    "            step_miou+=alliou\n",
    "        step_miou /= mask.shape[0]\n",
    "        iou /= mask.shape[0]\n",
    "        val_miou += step_miou\n",
    "\n",
    "        if val_iou is None:\n",
    "            val_iou=iou\n",
    "        else:\n",
    "            val_iou+=iou\n",
    "\n",
    "    print('Val Loss:{} Val Miou:{}, Class Miou:{}'.format(val_loss/len(eval_loader), val_miou/len(eval_loader),val_iou/len(eval_loader)))\n",
    "\n",
    "    return val_miou/len(eval_loader)\n",
    "\n",
    "\n",
    "def train(model, mode='train',epoches_override=None):\n",
    "    key='learning_strategy'\n",
    "    if mode=='warmup':\n",
    "        key+='_warmup'\n",
    "\n",
    "    strategy=train_parameters[key]\n",
    "\n",
    "    scheduler = get_scheduler(model, strategy)\n",
    "    assert scheduler\n",
    "\n",
    "    optimizer = get_optimizer(model, scheduler)\n",
    "    assert optimizer\n",
    "\n",
    "    train_loader = paddle.io.DataLoader(train_dataset,\n",
    "                        batch_size=strategy['batch_size'],\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        num_workers=strategy[\"workers\"])\n",
    "\n",
    "    eval_loader = paddle.io.DataLoader(eval_dataset,\n",
    "                        batch_size=strategy['batch_size'],\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        num_workers=strategy[\"workers\"])\n",
    "\n",
    "\n",
    "    loss = get_losses()\n",
    "\n",
    "    epoches=strategy['epochs']\n",
    "    if epoches_override is not None:\n",
    "        epoches = epoches_override\n",
    "\n",
    "    best_miou=0\n",
    "    for epoch in range(1,epoches+1):\n",
    "        # with paddle.amp.auto_cast():\n",
    "        train_one_epoch(model,epoch,epoches,optimizer,scheduler,loss,train_loader)\n",
    "        \n",
    "        save_checkpoint(model,epoch)\n",
    "        \n",
    "        with paddle.no_grad():\n",
    "            iou=eval_one_epoch(model,epoch,epoches,optimizer,loss,eval_loader)\n",
    "            if iou>=best_miou:\n",
    "                save_model(model,iou)\n",
    "                best_miou=iou\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d809c-63a4-4c47-bb79-cd31e85e01de",
   "metadata": {},
   "source": [
    "## 调用以上函数进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b4c73-cd3f-4b13-94ab-1c761cf94de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T14:55:46.881892Z",
     "iopub.status.busy": "2022-06-18T14:55:46.881557Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0618 22:55:46.885257 16705 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0618 22:55:46.890126 16705 gpu_context.cc:306] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-18 22:55:50 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "2022-06-18 22:55:51 [INFO]\tThere are 275/275 variables loaded into ResNet_vd.\n",
      "Epoch 0: CosineAnnealingDecay set learning rate to 0.005.\n",
      "Start Training...\n",
      "Epoch/Epochs:1/96\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:278: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.bool, the right dtype will convert to paddle.float32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "55it [01:42,  1.88s/it]"
     ]
    }
   ],
   "source": [
    "from model.utils.freezer import Freezer\n",
    "\n",
    "model=get_trained_model()\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab8f738-bff4-48db-964a-698b23e12120",
   "metadata": {},
   "source": [
    "## 生成提交结果\n",
    "对测试集进行预测并打包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92496d3e-15b6-4f78-895d-52ae978eb76d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "model = get_trained_model()\n",
    "\n",
    "state_path = find_lastest()\n",
    "assert state_path is not None\n",
    "model.set_state_dict(paddle.load(state_path))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_base = train_parameters['data_path']+\"test/\"+'img_testA/'    # 测试集路径\n",
    "out_base = 'data/result/'        # 预测结果保存路径\n",
    "\n",
    "# 是否存在结果保存路径，如不存在，则创建该路径\n",
    "if not os.path.exists(out_base):\n",
    "    os.makedirs(out_base)\n",
    "\n",
    "# 模型预测并保存预测图片\n",
    "for im in tqdm(os.listdir(test_base)):\n",
    "    if not im.endswith('.jpg'):\n",
    "        continue\n",
    "        \n",
    "    pt = test_base + im\n",
    "    img = Image.open(pt)\n",
    "\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB') \n",
    "\n",
    "    img = img.resize((512,512), Image.BILINEAR)\n",
    "    img = np.array(img).astype('float32')\n",
    "    img = img.transpose((2, 0, 1)) / 255\n",
    "\n",
    "    pred = model(paddle.to_tensor([img]))\n",
    "    result = np.argmax(pred[0].numpy(), axis=1)\n",
    "    result = result[0]\n",
    "\n",
    "    assert_is_label(result)\n",
    "    result = cv2.resize(result,dsize=(256, 256),interpolation=cv2.INTER_NEAREST)\n",
    "    assert_is_label(result)\n",
    "\n",
    "    cv2.imwrite(out_base+im.replace('jpg', 'png'), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3e2a5-a85e-4ed5-a7df-fe08d1ed5ef4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!zip -r result.zip data/result/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
